{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Unveiling the Crystal Ball of Education\"\n",
    "subtitle: Team Java\n",
    "author: Julia Chu, Victoria Shi, Yiru Zhang, and Yuyan Zhang\n",
    "date: 02/27/2023\n",
    "number-sections: true\n",
    "abstract: _Using data from two Portuguese secondary schools, this project examines the connection between individual factors and educational outcomes. Focusing on inference rather than prediction, this study creates three classification models to investigate the explanatory correlation between student demographics, social and school-related characteristics, and the final year grade, G3. The findings indicate that past evaluations have a significant impact on student achievement, and that education attendance plays a significant role in determining educational success regardless of socioeconomic and demographic factors. In addition, the study suggests that policymakers and educators prioritize improving attendance rates and provide targeted support for students who are struggling. Parents can also play an important role in their children's education. The study concludes that additional research is required to identify additional strategies for enhancing academic achievement_.\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    self-contained: true\n",
    "    font-size: 100%\n",
    "    toc-depth: 4\n",
    "    mainfont: serif\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Background / Motivation\n",
    "Education is fundamental to one's own growth and that of society in its entirety as it equips individuals with the information, abilities, and morals they'll need to thrive in modern life. Certainly not always, but quite frequently. Gains in income, decreased poverty, and increased productivity all point to it as a major factor in the expansion of the economy and the improvement of social conditions.\n",
    "\n",
    "Our research will look into what role personal attributes play in explaining academic success or failure.Â "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ff1421",
   "metadata": {},
   "source": [
    "## Problem statement \n",
    "\n",
    "Describe your problem statement. Articulate your objectives using absolutely no jargon. Interpret the problem as inference and/or prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7b95f",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "The information was obtained from [Kaggle](https://www.kaggle.com/datasets/dipam7/student-grade-prediction). In reality, though, the data originates from the UCL Machine Learning Repository and the [University of Minho in Portugal](https://pcortez.dsi.uminho.pt/). The data set contains student demographic and performance statistics from two Portuguese secondary schools. And we intend to identify the specific characteristics (which will serve as our predictors) that influence the final G3 grade for the year (outcome variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c255035",
   "metadata": {},
   "source": [
    "## Stakeholders\n",
    "A wide variety of stakeholders, such as parents, students, professionals working in the education business, economists, and policymakers, could perhaps have an interest in our projects. It is possible that through examining the dataset and gaining insights, we can discover ways in which school curricula can be improved as well as methods by which policymakers and economists can provide better support for future generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9994e",
   "metadata": {},
   "source": [
    "## Data cleaning and quality check ( Julia?)\n",
    "\n",
    "\n",
    "In a tabular form, show the distribution of values of each variable used in the analysis - for both categorical and continuous variables. Distribution of a categorical variable must include the number of missing values, the number of unique values, the frequency of all its levels. If a categorical variable has too many levels, you may just include the counts of the top 3-5 levels.\n",
    "\n",
    "If the tables in this section take too much space, you may put them in the appendix, and just mention any useful insights you obtained from the data quality check that helped you develop the model or helped you realize the necessary data cleaning / preparation.\n",
    "\n",
    "Were there any potentially incorrect values of variables that required cleaning? If yes, how did you clean them?\n",
    "\n",
    "Did you do any data wrangling or data preparation before the data was ready to use for model development? Did you create any new predictors from exisiting predictors? For example, if you have number of transactions and spend in a credit card dataset, you may create spend per transaction for predicting if a customer pays their credit card bill. Mention the steps at a broad level, you may put minor details in the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Data preparation and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548a002",
   "metadata": {},
   "source": [
    "It is important to note that the data used in this analysis has no missing values. However, this may not reflect the typical cleanliness and completeness of real-world data sets, which often contain missing or inconsistent values and require more extensive cleaning and preparation. In future work, it will be important to take these considerations into account and apply appropriate data cleaning and preparation techniques to ensure the validity of the results.\n",
    "\n",
    "In the data preparation phase, several steps were taken to transform and prepare the data for analysis. The following is a summary of the steps taken:\n",
    "\n",
    "- Identification of categorical variables: All columns in the data frame were reviewed to identify the categorical variables. A loop comprehension was used to find the number of unique values corresponding to each column, and this information was used to decide on the data processing approach.\n",
    "- Conversion of yes-no variables to binary variables: The code created a dictionary for binary mapping and applied it to all columns in the data frame that contained 'yes' or 'no' as the response.\n",
    "- Transformation of predictors with 2 unique values: The code transformed predictors with two unique values into binary variables by mapping them to 0 or 1. This was done for variables such as \"school\", \"sex\", \"famsize\", \"address\", and \"Pstatus\".\n",
    "- Creation of new predictors: To handle variables with more than two unique values, the code created dummy variables using the \"get_dummies\" function in pandas. The dummy variables were created for the \"Mjob\", \"Fjob\", \"reason\", and \"guardian\" columns. The original columns were then dropped, and the dummy variables were concatenated with the original data frame.\n",
    "- Combination of correlated predictors: The code combined the \"Dalc\" and \"Walc\" columns into a single \"Alc\" column to reduce correlation between the two variables, and combined the \"Fedu\" and \"Medu\" columns into a single \"famEdu\" column to capture the combined education of both parents. This helped to reduce data redundancy and the noise in the data set, and removed the multicollinearity.\n",
    "- Conversion of data types: The original data frame, which consisted of both categorical and numerical values, was converted into one that only consisted of numerical data types or uint8. This made it easier and more convenient for later variable selection and model development.\n",
    "\n",
    "In conclusion, the data cleaning and preparation phase transformed and prepared the data for analysis by converting categorical variables into binary or numerical values, combining correlated predictors, and converting the data types into a more convenient format for analysis. These steps helped to ensure the validity of the results and facilitated later variable selection and model development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb11c9b",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd74a9",
   "metadata": {},
   "source": [
    "Put the relevant EDA here (visualizations, tables, etc.) that helped you figure out useful predictors for developing the model(s). Only put the EDA that ended up being useful towards developing your final model(s). \n",
    "\n",
    "List the insights (as bullet points) you got from EDA that ended up being useful towards developing your final model. \n",
    "\n",
    "Again, if there are too many plots / tables, you may put them into appendix, and just mention the insights you got from them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc597c8",
   "metadata": {},
   "source": [
    "1. During the base model development, we transformed the response variable G3 grade into a binary variable using the common pass/fail boundary as the standard. In an exam worth a total of 20 points, a grade of 12 or higher is considered passing, while anything below is deemed failing. We used this standard to classify if a student passes or fails consistently throughout the analysis. We plotted the grade distribution in its raw format (out of 20) and in its binary form, respectively, to visualize the general distribution of student grades.\n",
    "2. Period 1 (`G1`) and Period 2 (`G2`) grades are strongly correlated with each other, as evidenced by the darker shade on the pairwise correlation plot.\n",
    "3. Period 1 (`G1`) and Period 2 (`G2`) grades are highly indicative of the final grade (`G3`), as evidenced by the scatterplot displaying the relationship between `G1` and `G2`, with data points colored based on `G3`.\n",
    "4. Both the bar plot based on importance score of the decision tree and the line plot demonstrate that `absences` and `failures` are crucial for predicting the final grades, with grades decreasing as absences and failures increase.\n",
    "5. `Medu` (mother's education) and `Fedu` (father's education) are strongly correlated, so we combined `Medu` and `Fedu` into `famEdu` (family education).\n",
    "6. `Dalc` (weekday alcohol consumption) and `Walc` (weekend alcohol consumption) are strongly correlated, so we combined `Dalc` and `Walc` into `Alc` (alcohol consumption).\n",
    "7. A new correlation plot after removing and combining predictors shows that major dependencies among predictors have been resolved.\n",
    "8. Categorical predictors like parents' jobs (`Mjob` and `Fjob`) also affect a student's grades. However, due to the difficulty in generalizing their impact across various categories, we did not focus on this factor during the base model development. Nevertheless, it remains an important aspect to consider in future analyses or more specialized models.\n",
    "\n",
    "\n",
    "For the model that predicts progress between different tests, the insights used are different form the insights used for the base model because we have created new categorical variables as our responses: `G1_G2` and `G2_G3`, which will be 1 if a student improves from the previous test and 0 if a student gets the same or lower score. I visualize the relationship between the predictors and `G1_G2` and `G2_G3` using barplots because a lot of the predictors are binary and other types of plots make it hard to observe the trend. Here are some findings: \n",
    "\n",
    "1. Observing the barplots of the predictors versus `G1_G2`, I see that the predictors `age`, `reason_other`, `Mjob other`, `romantic`, and `Fjob_services` have some kind of relationship with our response variables: as their values change, the mean of the reponse variable will change relatively more than the plots for other predictors. Note: I did not include all the graphs in the code file because we have 43 predictors in the dataset. \n",
    "\n",
    "2. Similarly, based on the barplots of predictors versus `G2_G3`, the variables `Mjob_teacher`, `famrel`, and `reason_course` seem to have the most effect on the reponse variable as the predictors' values change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "What kind of a model (linear / logistic / other) did you use? What performance metric(s) did you optimize and why?\n",
    "\n",
    "Is there anything unorthodox / new in your approach? \n",
    "\n",
    "What problems did you anticipate? What problems did you encounter? Did the very first model you tried work? \n",
    "\n",
    "Did your problem already have solution(s) (posted on Kaggle or elsewhere). If yes, then how did you build upon those solutions, what did you do differently? Is your model better as compared to those solutions in terms of prediction / inference?\n",
    "\n",
    "**Important: Mention any code repositories (with citations) or other sources that you used, and specifically what changes you made to them for your project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa761aba",
   "metadata": {},
   "source": [
    "---\n",
    "During Data Exploration, we realized it will remain difficult for us to  predicting a score from 0-20 using predictor variables that are (mostly) binary in value. This can be problematic because binary variables typically have a non-linear relationship with the outcome variable, and it can be difficult to predict a continuous score with such data. Moreover, using all categorical close-to-binary data for a prediction problem from a scale of 0-20 is a bad idea because it can result in inaccurate predictions and may not capture the nuances of the data. Therefore, we chose to approach the research question with classification method. \n",
    "\n",
    "We developed three models for different use cases:\n",
    "1. Base model to use for inference: What predictors have the most impact on students' final grade?\n",
    "2. Nested regression model for prediction: Which students are expected to do well in the class based on performance earlier in the semester?\n",
    "3. Progress model: What factors are most associated with students improving between from the first grading period to the second, and second grading period to the third?\n",
    "\n",
    "The metric that we care the most during classification is around the concern that we don't want to neglect students that really need help with their grades. Predicting a student neeeds help while they don't actually need is not as harmful as predicting a student who really needs help (might fail) as someone passing. Translating to the language in the confusion matrix, we care the most about minimizing FPR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab331a",
   "metadata": {},
   "source": [
    "## Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ec4c9",
   "metadata": {},
   "source": [
    "Explain the steps taken to develop and improve the base model - informative visualizations / addressing modeling assumption violations / variable transformation / interactions / outlier treatment / influential points treatment / addressing over-fitting / addressing multicollinearity / variable selection - stepwise regression, lasso, ridge regression). \n",
    "\n",
    "Did you succeed in achieving your goal, or did you fail? Why?\n",
    "\n",
    "**Final model equation**.\n",
    "\n",
    "Progress model: \n",
    "\n",
    "G1_G2 = 6.3710 - 0.4348* age + 0.9210* reason_other + 0.5279* Mjob_other - 0.4735* roantic - 0.1581* famrel\n",
    "\n",
    "G2_G3 = -2.4021 + 0.6112* Mjob_teacher - 0.4904* reason_course + 0.3824* famrel\n",
    "\n",
    "\n",
    "\n",
    "**Important: This section should be rigorous and thorough. Present detailed information about decision you made, why you made them, and any evidence/experimentation to back them up.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a581854",
   "metadata": {},
   "source": [
    "In this study, a classification approach was used to predict student performance. However, this was not a logistic regression classification problem. Instead, the response was manually categorized by setting a threshold and assigning values greater than the threshold as \"pass\" and values less than or equal to the threshold as \"fail\". This manual categorization approach is a valid method for solving this . By setting the threshold and categorizing the response, it is possible to effectively convert the continuous response into a categorical response, which can then be used for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49795297",
   "metadata": {},
   "source": [
    "### Base Model Development\n",
    "\n",
    "Several techniques were used to develop and evaluate the model for the initial and variable selection phase and base model development. The following is a summary of the techniques used:\n",
    "\n",
    "- K-Fold cross-validation and train-test split: K-Fold cross-validation and train-test split were used to assess the model's accuracy. In K-Fold cross-validation, the data was divided into K equal parts, and the model was trained and tested K times, with each part being used as the test set once. In the train-test split, the data was divided into a training set and a validation set, and the model was trained on the training set and tested on the validation set.\n",
    "\n",
    "Two different feature selection methods were employed to identify the most important quantitative and categorical predictors.\n",
    "\n",
    "For identifying the most important categorical predictors, the SelectKBest method with the chi-square test was used. First, only the categorical columns were extracted from the dataset. Then, the SelectKBest method was applied to choose the top 5 features based on their chi-square scores. The scores were stored in a pandas Series object and sorted in descending order to display the most significant categorical predictors.\n",
    "\n",
    "- Decision tree search:  To select the most important quantitative predictors, a Decision Tree Regressor model was fitted to the training data. We used `DecisionTreeRegressor` as opposed to `DecisionTreeClassifier` as we were treating the problem as a prediction problem on the first hand, followed by manual classification based on the pass/fail threshold.  Feature importances were calculated, and used a horizontal bar plot was created to visualize the top 10 features with the largest importance values. Variables `failures` and `absences` were identified as the two most important features.\n",
    "\n",
    "- Chi-square test variable selection: The chi-square test was used to select the most important categorical predictors by assessing the dependence between the categorical predictors and the target variable. `schoolsup` (extra educational support( and parents' job (mother's job `Mjob` and father's job `Fjob`) were important as relatively important predictors.\n",
    "\n",
    "Given the limitations of a non-linear regressor (`DecisionTreeRegressor`) in identifying important features for linear regression, more than one decision tree was built to analyze and identify the important features. While the selected features often vary,  the most important factors kept at each tree's top branch - features consistently selected as the most important ones regardless of trees built - were `failures` and `absences`. With this information, the base model was developed using only these 2 most important features, along with their interaction terms.\n",
    "\n",
    "Four models was fitted using all possible combinations of predictors `failures` and `absences`:\n",
    "1. $G3 \\sim absences$\n",
    "2. $G3 \\sim failures$\n",
    "3. $G3 \\sim absences + failures$\n",
    "4. $G3 \\sim absences * failures$\n",
    "\n",
    "All achieved a 100% accuracy on the training and testing data. Accuracy was used as the only metric at this stage, as it provides a direct measure of the model's basic performance without giving weight to the cost of different errors. Later, more refined metrics will be used to weigh the priorities and relative costs of different types of errors.\n",
    "\n",
    "We chose $G3 \\sim absences * failures$ as the final base model as it captures the meaningful relationship of these two features and their combined effect on predicting student grades (`G3`). The term `absences:failures` has a P-value as small as 1.473151e-03. The extremely small P-value means that the interaction is statistically significant.The other models, although achieving an accuracy of 1.0 on the test set and the full dataset, do not account for the interaction between absences and failures. This could lead to a less accurate prediction of student grades in real-world scenarios where the the effect of absences on student grades is not constant across students who have experienced different levels of failures. By including the interaction term, the last model better accounts for the combined influence of absences and failures on student grades, making it the best choice among the four models presented.\n",
    "\n",
    "Final base model: $$G3 \\sim absences * failures$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a55bb1",
   "metadata": {},
   "source": [
    "### Nested Model Development\n",
    "The nested model was developed through manual trial and error, by adding predictor identified as possibly important during EDA to see if it improves prediction accuracy.\n",
    "\n",
    "With just `G1` and `G2` as predictors, the model was able to predict whether `G3` grade fell in the top or bottom 50% of the class with an accuracy of 94.3% on train data and 91.1% on test data. Since `G1` and `G2` are collinear, the model is not useful for inference, but multicollinearity is ignored as it does not effect prediction.\n",
    "\n",
    "With the results of those predictions, the data is split into two dataframes based on the result of the first logistic regression. All the possible additional predictors identified during EDA were added to the model, but all except were removed from due to high coefficient p-values, meaning that the predictors were likely insignificant.\n",
    "\n",
    "For the modeling predicting whether the upper 50% subset, falls into the third of fourth quantile, a similar approach was taken. For that model, the most significant predictor is `G2`. With that predictor alone was able to classify train data with 94.2% accuracy and test data with 100% accuracy. Adding other predictors did not increase the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db21c478",
   "metadata": {},
   "source": [
    "### Progress Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42722f3",
   "metadata": {},
   "source": [
    "In the development of the progress model, the result from previous models do not seem to work. I tried to use the same predictors to build logistic models for G1_G2 and G2_G3 but there are several problems that we encounter:\n",
    "\n",
    "1. Models are not significant: best LLR p-value achieved for the model for G1_G2 is around 0.01, which is far less than other models built in this project. \n",
    "2. Many variables are insignificant as the p-value for individual coefficient is hight.\n",
    "3. Measurements of accuracy of classification are largely affected by the chosen threshold: even if we change the threshold by 0.01, there might be huge change in the observations that belong to FN and FP, so we need to balance between accuracy and recall.\n",
    "4. After we balance the measurements and choose a fixed threshold, the highest accuracy/recall is less than 65% and the lowest FPR/FNR is larger than 35%\n",
    "5. We also tried to calculate ROC-AUC, which is independent from the threshold, and the value is only around 0.65. \n",
    "\n",
    "This part of the exploration is not shown in the code file, but based on this attempt, the direction of the pregress model is completely different from the base model: we will do new variable selection and new models.\n",
    "\n",
    "To select the best predictors, Lasso is performed on the train dataset twice, because we need two new models for G1_G2 and G2_G3. We definitely don't want too many predictors in our models because giving too many advices to the students and families might make them feel overwhelmed. Therefore, I selected five predictors based on the absolute values of the coefficients after Lasso. It turns out that they match with our EDA but have small differences. \n",
    "\n",
    "For the model built for G1_G2, there is one selected variable from Lasso that is different from the variables selected in EDA, so I build two models and compare them. Since our main concern is to help students and we don't want to leave out any student who actually needs help. In other words, predicting a student as able to improve when they cannot (False positives) will be harmful because the teacher will put effort in this student. Thus, the most important metric in the classification of improvement is FP. The model based on Lasso has lower FPR and other measurements are reasonable, so we will use progress_model_1_1 to predict whether a student improves from the first test to the second test. \n",
    "\n",
    "We will have similar consideration for the two models builts for G2_G3. However, in this scenario, the model built using the predictors from Lasso has much higher recall (43.8) than model using predictors from EDA (25%) while the FPR of the Lasso model (41.2%) is much higher than the FPR of the model using EDA (28.8%). Since both models have an obvious disadvantage, we will select the final model based on what we concern more--FPR, so we will use progress_model_2_2 to predict whether a student improves from the second test to the final test. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b46343d",
   "metadata": {},
   "source": [
    "## Limitations of the model with regard to inference / prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ead90",
   "metadata": {},
   "source": [
    "If it is inference, will the inference hold for a certain period of time, for a certain subset of population, and / or for certain conditions.\n",
    "\n",
    "If it is prediction, then will it be possible / convenient / expensive for the stakeholders to collect the data relating to the predictors in the model. Using your model, how soon will the stakeholder be able to predict the outcome before the outcome occurs. For example, if the model predicts the number of bikes people will rent in Evanston on a certain day, then how many days before that day will your model be able to make the prediction. This will depend on how soon the data that your model uses becomes available. If you are predicting election results, how many days / weeks / months / years before the election can you predict the results. \n",
    "\n",
    "When will your model become too obsolete to be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e398f",
   "metadata": {},
   "source": [
    "---\n",
    "The objective of the research project was to classifyÂ the performance of secondary school students in two Portuguese secondary schools. Unfortunately, the study contains a number of inference limitations. First, the dataset is from 2008, therefore it may not reflect the current educational scene. In addition, the study had 395 observations in total, which increases the danger of overfitting and makes it challenging to apply the results to a larger population. In addition, the study was done in Portugal, which may limit its applicability to other nations or areas.Â \n",
    "\n",
    "Future study could benefit from increasing the dataset to include a larger sample size and a broader range of demographic and socioeconomic variables, potentially encompassing a variety of nations. This would allow for more rigorous studies and findings that may be applied to a wider range of population types. It may aid in the identification of gaps in educational results and provide insight into potential interventions that may be implemented to assist underrepresented populations.  Inclusion of a larger range of indicators, such as cultural influences, mental health, and family environment, could further illuminate the intricate relationship between individual determinants and educational results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6026cb7",
   "metadata": {},
   "source": [
    "## Other sections *(optional)*\n",
    "\n",
    "You are welcome to introduce additional sections or subsections, if required, to address any specific aspects of your project in detail. For example, you may briefly discuss potential future work that the research community could focus on to make further progress in the direction of your project's topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a185cb",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations to stakeholder(s)\n",
    "\n",
    "What conclusions do you draw based on your model? If it is inference you may draw conclusions based on the coefficients, statistical significance of predictors / interactions, etc. If it is prediction, you may draw conclusions based on prediction accuracy, or other performance metrics.\n",
    "\n",
    "How do you use those conclusions to come up with meaningful recommendations for stakeholders? The recommendations must be action-items for stakeholders that they can directly implement without any further analysis. Be as precise as possible. The stakeholder(s) are depending on you to come up with practically implementable recommendations, instead of having to think for themselves.\n",
    "\n",
    "If your recommendations are not practically implementable by stakeholders, how will they help them? Is there some additional data / analysis / domain expertise you need to do to make the recommendations implementable? \n",
    "\n",
    "Do the stakeholder(s) need to be aware about some limitations of your model? Is your model only good for one-time use, or is it possible to update your model at a certain frequency (based on recent data) to keep using it in the future? If it can be used in the future, then for how far into the future?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f772f64",
   "metadata": {},
   "source": [
    "---\n",
    "Notwithstanding the limits of the current data set, the findings show the importance of attendance and previous assessments in predicting student achievement, which can be utilized to drive policy decisions and improve student educational outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274e262",
   "metadata": {},
   "source": [
    "*Bsed on  the base model - Victoria*\n",
    "1. Absences and failures are important quantitative predictors in determining a student's grades. As such, it is essential to consider these factors when developing early warning systems aimed at ensuring the academic success of students who may be susceptible to these challenges. By closely monitoring students' attendance and performance, educators can intervene proactively and provide tailored support to help students overcome the obstacles that absences and failures may present. Implementing such a system will not only help to identify students at risk but also enable timely interventions that can significantly enhance their chances of academic success and overall well-being.\n",
    "2. School support and parents' jobs have emerged as important quantitative predictors of students' grades in our analysis. These factors significantly influence a student's academic performance, highlighting the need to consider them when designing early warning systems. By identifying students who may be susceptible to the challenges associated with limited school support or specific parental occupations, targeted interventions can be developed to ensure their academic success. Incorporating these predictors into an early warning system allows schools and educators to proactively address potential issues, providing tailored support and resources to help students overcome these odds and achieve their full potential.\n",
    "\n",
    "*Insights derived from the nested model - Yuyan*\n",
    "\n",
    "*Insights derived from the nested model - Yiru*\n",
    "\n",
    "5. Mother's job plays a important part for both the improvement from G1 to G2 and G2 to G3. This variable Mjob consists the categories 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other', and being a teacher and other jobs have positive relationship with the increase in grade for students. I believe probably health care and civil service jobs require a lot of time and effort, and mothers do not have enough time to accompany their kids and help with their learning. Also, housewives might not have enough knowledge to help their kids study.\n",
    "\n",
    "6. Also, the reason why a students chooses this school is related to their progress. The variable consists of values: close to 'home', school 'reputation', 'course' preference or 'other'. From the two models, reason_other has positive coefficient in the model for G1_G2 and reason_course has negative coefficient in the model for G2_G3. I think one major category that contains in 'other' might be achieving personal growth and learn knowledge, and this could stimulate student's interest in studying, and thus improvement in scores. In contrast, if the student only thinks the courses are interesting, they will not care much about their grades, so the coefficient in front of reason_course will be negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44497c",
   "metadata": {},
   "source": [
    "## GitHub and individual contribution {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b3f66",
   "metadata": {},
   "source": [
    "[Github link](https://github.com/Juliaaaachu/LinearModel_Stat303-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505da5c",
   "metadata": {},
   "source": [
    "<html>\n",
    "<style>\n",
    "table, td, th {\n",
    "  border: 1px solid black;\n",
    "}\n",
    "\n",
    "table {\n",
    "  border-collapse: collapse;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "th {\n",
    "  text-align: left;\n",
    "}\n",
    "    \n",
    "\n",
    "</style>\n",
    "<body>\n",
    "\n",
    "<h2>Individual contribution</h2>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <colgroup>\n",
    "       <col span=\"1\" style=\"width: 15%;\">\n",
    "       <col span=\"1\" style=\"width: 20%;\">\n",
    "       <col span=\"1\" style=\"width: 50%;\">\n",
    "       <col span=\"1\" style=\"width: 15%;\"> \n",
    "    </colgroup>\n",
    "  <tr>\n",
    "    <th>Team member</th>\n",
    "    <th>Contributed aspects</th>\n",
    "    <th>Details</th>\n",
    "    <th>Number of GitHub commits</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Julia Chu</td>\n",
    "    <td> EDA, Github Management</td>\n",
    "    <td> conducted initial exploratory data analysis along with visualization that provided insights for model development and variable transformation. </td>\n",
    "    <td>17</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Victoria Shi</td>\n",
    "    <td> Data preprocessing; EDA; feature selection; model development </td>\n",
    "    <td> Data preprocessing and preperation; exploratory data analysis for base model development; base model development; feature selection via statistical test; identified relevant variable interactions.</td>\n",
    "    <td>40</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Yiru Zhang</td>\n",
    "    <td>EDA and progress model development</td>\n",
    "    <td>explanatory data analysis for the progress model; visualization and variables selection; progress model development and assessment of prediction.</td>\n",
    "    <td>10</td>    \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Chun-Li</td>\n",
    "    <td>Variable selection and addressing overfitting</td>\n",
    "    <td>Performed variable selection on an exhaustive set of predictors to address multicollinearity and overfitting.</td>\n",
    "    <td>???</td>    \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bbd23",
   "metadata": {},
   "source": [
    "List the **challenges** you faced when collaborating with the team on GitHub. Are you comfortable using GitHub? \n",
    "Do you feel GitHuB made collaboration easier? If not, then why? *(Individual team members can put their opinion separately, if different from the rest of the team)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1cafe",
   "metadata": {},
   "source": [
    "## References {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb1aad",
   "metadata": {},
   "source": [
    "[1] P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance. In A. Brito and J. Teixeira Eds., Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) pp. 5-12, Porto, Portugal, April, 2008, EUROSIS, ISBN 978-9077381-39-7.\n",
    "\n",
    "[2] Dipam7. (2021). Student Grade Prediction [Data file]. Kaggle. https://www.kaggle.com/dipam7/student-grade-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5831751c",
   "metadata": {},
   "source": [
    "## Appendix {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d374d",
   "metadata": {},
   "source": [
    "You may put additional stuff here as Appendix. You may refer to the Appendix in the main report to support your arguments. However, the appendix section is unlikely to be checked while grading, unless the grader deems it necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
